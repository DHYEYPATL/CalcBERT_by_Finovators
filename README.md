# ğŸ“˜ **README.md â€” CalcBERT**

````md
# CalcBERT  
**Offline Transaction Categoriser â€” GHCI Hackathon**

CalcBERT is a lightweight, offline-first transaction categorisation system.  
It includes:
- A FastAPI backend (TF-IDF and DistilBERT models)
- A Streamlit UI
- A simple ML pipeline designed for speed, clarity, and hackathon-friendly iteration

---

# ğŸš€ Quickstart (Developers)

## 1) Clone the repo
```bash
git clone https://github.com/YOUR-USERNAME/CalcBERT.git
cd CalcBERT
````

## 2) Create Python environment

**Mac/Linux:**

```bash
python -m venv venv
source venv/bin/activate
```

**Windows (PowerShell):**

```bash
python -m venv venv
venv\Scripts\Activate.ps1
```

## 3) Install dependencies

```bash
pip install -r requirements.txt
```

---

# â–¶ï¸ Run the project

## Start Backend (FastAPI)

```bash
cd backend
uvicorn app:app --reload --port 8000
```

Backend will be at:
ğŸ‘‰ **[http://localhost:8000](http://localhost:8000)**

Test it:

```
GET http://localhost:8000/health
```

---

## Start UI (Streamlit)

Open a new terminal:

```bash
cd ui
streamlit run app.py --server.port 8501
```

UI runs at:
ğŸ‘‰ **[http://localhost:8501](http://localhost:8501)**

---

# ğŸ“‚ Project Structure

```
CalcBERT/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ model_adapter.py
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ predict.py
â”‚       â”œâ”€â”€ feedback.py
â”‚       â””â”€â”€ retrain.py
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ data_pipeline.py
â”‚   â”œâ”€â”€ normalize_map.json
â”‚   â”œâ”€â”€ tfidf_pipeline.py
â”‚   â”œâ”€â”€ train_tfidf.py
â”‚   â”œâ”€â”€ evaluate_tfidf.py
â”‚   â”œâ”€â”€ feedback_handler.py
â”‚   â””â”€â”€ distilbert_model.py
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ components/
â”‚       â””â”€â”€ explain_card.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demo_train_small.csv
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ categories.json
â”œâ”€â”€ saved_models/
â”‚   â”œâ”€â”€ tfidf/
â”‚   â””â”€â”€ distilbert/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_pipeline.py
â”‚   â””â”€â”€ test_tfidf_pipeline.py
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ tfidf_metrics.json
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start_all.sh
â”‚   â””â”€â”€ save_weights.sh
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

# ğŸ‘¥ Team Workflow (Hackathon-Optimised)

### Rules

* **Never commit directly to `main`**
* Always work on **feature branches**
* Branch format:
  `feature/<name>-<task>`
  â†’ Example: `feature/neha-tfidf`

### Start a feature

```bash
git checkout -b feature/<name>-<task>
```

### Save progress

```bash
git add .
git commit -m "short message"
git push -u origin feature/<name>-<task>
```

### Open a Pull Request (PR)

* Go to GitHub â†’ Repo
* You'll see *â€œCompare & pull requestâ€*
* Assign a teammate
* Merge after **1 approval**

---

# ğŸ§© Team Roles (suggested)

**Neha (ML)**

* `ml/data_pipeline.py`
* `ml/tfidf_pipeline.py`
* Add `data/demo_train_small.csv`

**Adya (ML)**

* `ml/distilbert_model.py`
* Optional: fusion/ensemble logic

**Dhyey (Backend)**

* `backend/app.py`
* `backend/model_adapter.py`
* `backend/routes/predict.py` + `feedback.py`

**Suchet (UI)**

* `ui/app.py`
* `ui/components/explain_card.py`

---

# ğŸ§ª Basic Testing

To run tests:

```bash
pytest
```

To quickly check backend:

```
GET http://localhost:8000/health
```

---

# ğŸ§± Model Weights Handling

To avoid large files messing up the repo:

* `saved_models/distilbert/` is ignored in `.gitignore`
* Store large `.pt` or `.bin` files in Google Drive
* Add download script in `scripts/save_weights.sh`

---

# ğŸ©¹ Troubleshooting

**Canâ€™t push?**

```bash
git pull origin main
# resolve conflicts
git add .
git commit -m "fix: merge conflicts"
git push
```

**Backend not reachable?**

* Ensure backend is running on port 8000
* UI should call: `http://localhost:8000/predict`

**Package missing?**

```bash
pip install -r requirements.txt
```

**Accidentally committed big model files?**
Remove them:

```bash
git rm --cached file.pt
echo "file.pt" >> .gitignore
```

---

# ğŸ“ PR Checklist

Before merging a PR:

* [ ] Code runs locally (backend + UI)
* [ ] PR description is clear
* [ ] No breaking changes unless documented
* [ ] New files follow folder structure
* [ ] No model weights or large files committed

---

# ğŸ¯ Ready for Hackathon

You now have:

* A clean repo
* Clear workflow
* Working backend and UI stubs
* Precise team responsibilities
* Easy local setup

Letâ€™s build CalcBERT ğŸš€

```
